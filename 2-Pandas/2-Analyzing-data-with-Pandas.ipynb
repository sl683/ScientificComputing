{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Data with Pandas \n",
    "Here, we continue our exploration of the Pandas package. We focus on various ways data stored in dataframes can be analyzed using the package. Specifically, we look at: \n",
    "1. [Calculating and updating fields](#1.-Calculating-and-updating-fields)\n",
    "* [Selecting data in a dataframe](#2.-Selecting-data-from-a-dataframe)\n",
    " 1. [Selecting single rows, select rows, or row slices using `iloc`](#2a.-Selecting-single-rows,-select-rows,-or-row-slices-using-iloc)\n",
    " 1. [Selecting rows and columns using `iloc`](#2b.-Selecting-rows-and-columns-using--iloc)\n",
    " 1. [Selecting rows and columns using `loc`](#2c.-Selecting-rows-and-columns-using--loc)\n",
    " 1. [Selecting rows based on criteria - using _queries_](#2d.-Selecting-rows-based-on-criteria---using-queries)\n",
    " 1. [Selecting rows based on criteria - using _masks_](#2e.-Selecting-rows-based-on-criteria---using-masks)\n",
    " 1. [Updating values in selected rows/columns](#2f.-Updating-values-in-selected-rows/columns)\n",
    "* [Grouping and aggregating data in a dataframe](#3.-Grouping-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial import of surveys dataset\n",
    "survey_df = pd.read_csv('../data/surveys.csv',\n",
    "                        index_col='record_id',\n",
    "                        dtype={'plot_id':'str'})\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculating and updating fields\n",
    "A typical operation in dataframes is creating new fields from values in other fields. We'll show this by computing hindfoodt_length (currently in mm) into inches. (25.4 mm per inch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a field of hindfoot length in inches\n",
    "survey_df['hindfoot_length_in'] = survey_df['hindfoot_length'] / 25.4\n",
    "\n",
    "#Review the output\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "► YOU TRY IT:\n",
    "* Create a new column \"weight_oz\" converting weigth (grams) into ounces (28.35 g/oz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a field of weight in ounces\n",
    "\n",
    "\n",
    "#Review the output\n",
    "survey_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting data from a dataframe\n",
    "We often want to isolate specific rows and/or columns of data from our dataframe for further analysis. Pandas offers many ways to do this. Here we'll review these techniques. \n",
    "\n",
    "### 2a. Selecting single rows, select rows, or row *slices* using `iloc`\n",
    "Recall that dataframes can be considered lists (rows) of lists (columns). As such, we can select specific rows by their **integer index**, either indivdually or in *slices*. This is done using the dataframe's `iloc` method.\n",
    "\n",
    "Refer to the [Pandas help on `iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) for more info on this functionality: \n",
    "> _**`iloc`** is short for integer location_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the 4th row of data\n",
    "survey_df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the 101st thru 110th rows of data\n",
    "survey_df.iloc[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the 3rd, 5th, and 10th rows\n",
    "survey_df.iloc[[2,4,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Selecting rows and columns using  `iloc` \n",
    "The `iloc` method can also be used to select columns. Which columns to select are passed as the second parameter in the `iloc` function. Therefore, we need to specify which rows we want to fetch first. If we want to retrieve the selected columns for all rows, we can just pass a \"`:`\" as the first parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all rows and the 4th column of the dataset\n",
    "survey_df.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the first 5 rows and the 4th column of the dataset\n",
    "survey_df.iloc[:5,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ ***So you see, selecting subsets is just a matter of messing around with the row/column integer indices and inserting them into the `iloc` method.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Selecting rows and columns using  `loc` \n",
    "While `iloc` selects rows and columns by their absolute _position_, `loc` selects rows and columns by their _labels_. Yes, each row and column has a label. A column's label is its ***column name***; a row's label is its ***label index*** (not to be confused with its _integer_ index, which is simply its row number).\n",
    "\n",
    "When Pandas reads in a CSV file, the CSV file determines the column names, but row labels are assigned a sequential numeric value by default. When we read in data into our `surveys_df`, we specified the values inthe `record_id` column to become our index, i.e., our row labels. We can now use these labels to select rows, and combine them with column names to select row/column combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the row with row label of 10\n",
    "survey_df.loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch value in the species_id column in the row with row label of 10 \n",
    "survey_df.loc[10,'species_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our dataframe's row index (i.e. its row labels) happens to be numeric, we can fetch slices of values. We can also fetch multiple columns by passing them in as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch value in the species_id column in the row with rows with labels between 10 and 20\n",
    "survey_df.loc[10:20,['species_id','sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Selecting rows based on criteria - using _queries_\n",
    "Instead of selecting data by position or by index, we can also query our dataframe for all records meeting specific criteria. In this first example, we'll use the dataframe's `query()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch all records from the year 1997 into a new variable\n",
    "records_1997 = survey_df.query('year == 1997')\n",
    "records_1997.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch all records from 1997 for female individuals\n",
    "females_1997 = survey_df.query('year == 1997 & sex == \"F\"')\n",
    "females_1997.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. Selecting rows based on criteria - using _masks_\n",
    "Queries are handy, but as more criteria are used, the query statement can get cumbersome. The use of masks provide a somewhat more simplified approach, or at least a more modular approach. \n",
    "\n",
    "A \"mask\" is a Python series (i.e. one column of data) with a Boolean values for each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask for all records with hindfeet smaller than 35mm\n",
    "mask_smallfeet = survey_df['hindfoot_length'] < 35\n",
    "mask_smallfeet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply this mask to select records where the mask value is true by using it with the `loc` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df.loc[mask_smallfeet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's nice about masks is that we can combine multiple masks. Think of each Boolean value as as on/off switch that determines whether or not the value is added to the final set. We use `&` [\"and\" switch] to combine switches such that each must be \"on\", and `|` [\"or\" switch] to require only one switch to be on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask of females\n",
    "mask_male = survey_df['sex'] == 'M'\n",
    "mask_male\n",
    "\n",
    "#Create a mask for records colected in April\n",
    "mask_april = survey_df['month'] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter records meeting all criteria\n",
    "data_subset = survey_df.loc[mask_smallfeet & mask_male & mask_april]\n",
    "data_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter records meeting any criteria\n",
    "data_subset = survey_df.loc[mask_smallfeet | mask_male | mask_april]\n",
    "data_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ►Knowledge check:\n",
    "* Use the `query()` function to select all male individuals with weight greater than 41 g. \n",
    " * What is the median hindfoot length of this population? \n",
    "* Perform the same analysis using masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract males weighing more than 41 g - using query\n",
    "subset = survey_df.query(\"sex == 'M' and weight > 41\")\n",
    "subset['hindfoot_length'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract males weighing more than 41 g - using masks\n",
    "mask_weight = survey_df['weight'] > 41\n",
    "subset_2 = survey_df.loc[mask_male & mask_weight]\n",
    "subset_2['hindfoot_length'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2f. Updating values in selected rows/columns\n",
    "We've learned how to select data in specific rows and columns. Now we'll update those values.\n",
    "\n",
    "Our dataset has some erroneous data: records occuring on the \"31st\" day of April (which has only 30 days in it). We'll replace those dates to be the 30th day of April. To do this, we have to select rows where the month is '4' and the day is '31'. And then with those rows selected, we'll update the the values in the day column to be 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create masks for day = 30 and month = 4\n",
    "mask_day = survey_df['day'] == 31\n",
    "mask_april = survey_df['month'] == 4 \n",
    "mask_sept = survey_df['month'] == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply the masks, it returns a dataframe of that selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the masks\n",
    "survey_df.loc[mask_day & (mask_april | mask_sept)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a column designation to just get one column with the selected rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch the just the day column of the filtered rows\n",
    "survey_df.loc[mask_day & (mask_april | mask_sept), 'day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just display to the screen, we can assign and new value to this selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the values\n",
    "survey_df.loc[mask_day & (mask_april | mask_sept), 'day'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What's the largest value in the day column for records where month = 4\n",
    "survey_df.query('month == 4 or month == 9')['day'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dates fixed, we can now create a date attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['date'] = pd.to_datetime(survey_df[['year','month','day']])\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Grouping data\n",
    "We often want to calculate summary statistics grouped by subsets or attributes within fields of our data. For example, we might want to calculate the average weight of all individuals per some variable like `species_id`, `plot_id` or `sex`. This is done by Pandas' `group_by()` function. \n",
    "\n",
    "So let's go through the process of grouping data by sex (a variable without a lot of unique values) and computing mean weight and mean hindfoot length of males vs females. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some review:\n",
    "* We can calculate summary statistics for **all** records in a single column using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also extract each single metric separately if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Min: \", survey_df['weight'].min())\n",
    "print(\" Max: \", survey_df['weight'].max())\n",
    "print(\" Mean: \", survey_df['weight'].mean())\n",
    "print(\" Std Dev: \", survey_df['weight'].std())\n",
    "print(\" Count: \", survey_df['weight'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To summarize by a categorical value, we group the data on that variable. The result of this operation is a new type of object - a Pandas \"DataFrameGroupBy\" object, which is an intermediate to doing analysis on grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data by unique values in the `sex` field\n",
    "grouped_data = survey_df.groupby('sex')\n",
    "\n",
    "#This creates a Panda's \"grouped dataframe\" object\n",
    "type(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To analyze the grouped dataframe object, we supply an aggregate function like `min()`, `median()`, `count()` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the median value of all numeric fields for each group\n",
    "grouped_data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a list of fields if you want to restrict what columns are reported\n",
    "grouped_data[['hindfoot_length','weight']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, use the describe function to reveal all summary stats for the grouped data\n",
    "grouped_data['weight'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color='red'>Challenge - Summary Data </font>\n",
    "1. How many recorded individuals are female `F` and how many male `M`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Show the *count* of records, grouped by sex\n",
    "#grouped_data.█()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The statement above produces another dataframe. Show just the count of the records in the `weight` field in the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challege 2: Just show the 'month' column in the above statement\n",
    "#grouped_data.█()['█']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What happens when you group by two columns using the following syntax and then grab mean values:\n",
    " * `grouped_data2 = survey_df.groupby(['plot_id','sex'])`\n",
    " * `grouped_data2.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Display summary statistics of **hindfood length** values for each **plot id** in your data.  \n",
    "_HINT: First group data, then extract the one variable you want to summarize, and finally use the `describe` function on that result to compute summary statistics..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *More complex aggregating functions...*\n",
    "We can also supply a **dictionary of aggregating functions** so that each column in the grouped result is aggregated exactly how we want (i.e. instead of computing just the sum or mean of all columns). This dictionary is built by specifying the <u>column name as the key</u> and the <u>aggregate function(s) as the values</u>. Below is an example to aggregate the data by `sex`, computing the minumum and maximum of the `year`, the median of the `hindfoot_length`, and the mean `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the aggregate function dictionary\n",
    "aggFuncs = {\n",
    "    \"year\": ['count','min','max'],#compute count, min, and max of the year attribute\n",
    "    \"hindfoot_length\": 'median',  #compute the median hindfoot length\n",
    "    \"weight\": 'mean'}             #compute the mean weight\n",
    "#Apply the dictionary\n",
    "survey_df.groupby('sex').agg(aggFuncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transforming data with pivot tables\n",
    "And finally, we can transform our data via pivot tables. In this operation, we take two categorical values in our data set, creating row labels with one and column names with the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df.pivot_table(\n",
    "    values = 'weight',\n",
    "    index = 'species_id',\n",
    "    columns= 'year',\n",
    "    aggfunc ='mean'\n",
    ").fillna(-1).T.style.background_gradient(cmap = 'YlGnBu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
